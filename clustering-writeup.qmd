---
title: "How groups are assigned for the Calculus Workshop"
format: html
execute: 
  warning: false
  message: false
---

```{r}
library(tidyverse)
library(googlesheets4)
```

## Introduction

Students are assigned to groups to boost team building in the Bren Calculus Workshop. The process is included here with personal information masked for transparency and to continue to show students the power of R and data science. Skills greatly needed to succeed at Bren.

## Data import

First we need to get the data in from the Google form responses. For that we use the `googlesheets4` package. Normally you have to connect it to your gmail account the first time you use it, but I've already done that behind the scences. All we need to do is provide the google sheet url link.

```{r, echo=FALSE}

data<-read_sheet("https://docs.google.com/spreadsheets/d/1EwUbwXUpAQvpXuF_zvK4aCXOP9ucYuam_r3xBgZ6cKw/edit?resourcekey#gid=967303810") %>% 
  janitor::clean_names() %>% 
  select(-timestamp)
```
```{r, echo=TRUE,eval=FALSE}

data<-read_sheet("url to google sheet") %>% 
  janitor::clean_names() %>% 
  select(-timestamp)
```

## Constrained K-means clustering

K-means clustering is machine learning algorithm that groups objects of the nearest type to each other. Here, I used constrained k-means clustering as I need to have set sizes of groups to randomly sample from. The basic idea is that everyone's responses to the questionnaire should place them similarly along multiple dimensions. K-means will find those groups for me so I can then randomly pull out of those groups to make teams with at least one person comfortable with math, another not so comfortable, and the range in between. 

You will learn all about this procedure in ESM 244 (with me as instructor!)

The first step in the cleaning process is to turn all those funny category names into numeric values for the algorithm to group. I use a likert scale to approximate the responses numerically. 

```{r}
colnames(data)<-c("specialization","major","math_level","use","relationship","name")
```

```{r}

likert<-data %>% 
  mutate(specialization=case_when(
    specialization=="Business and Sustainability"~1,
    specialization=="Environmental Policy"~2,
    specialization=="Coastal Resources and Management"~3,
    specialization=="Energy and Climate"~5,
    specialization=="Water Resources Management"~4,
    specialization=="Pollution Prevention and Remediation"~6,
    specialization=="Conservation Planning"~7
  )) %>% 
  mutate(major=case_when(
    major=="Humanities (History, Literature, Art)"~1,
    major=="Business"~2,
    major=="Political Science"~3,
    major=="Environmental Science"~4,
    major=="STEM (Biology, Chemistry, Physics)"~5,
    major=="Economics"~6,
    major=="Computer Science"~7
  )) %>% 
  mutate(math_level=case_when(
    math_level=="Algebra"~1,
    math_level=="Trigonometry"~2,
    math_level=="Calculus 1"~3,
    math_level=="Calculus 2"~4,
    math_level=="Calculus 3 and beyond (Diff eq, real analysis, if you know what those are click this option)"~5
  )) %>% 
  mutate(use=case_when(
    use=="Less than a year"~1,
    use=="1-2 years ago"~2,
    use=="3-5 years ago"~3,
    use=="Not since the dark times (5+ years)"~4
  )) %>% 
  mutate(relationship=case_when(
    relationship=="My mortal enemy"~1,
    relationship=="Your crazy, high key racist uncle you have to invite to Thanksgiving"~2,
    relationship=="The friend of a friend who's name you can never remember"~3,
    relationship=="Respectful co-worker you can have a beer with"~4,
    relationship=="My best friend!"~5
  ))

df<-likert %>% 
  select(-name) %>% 
  as.matrix() %>% 
  unname()
```

Now that all that mess is done, for this demonstration I will create random people with random responses to make sure the actual information of the students is protected.

```{r}
## Practice data_frame with a "fully" populated sample

set.seed(1)
prac<-data.frame(spec=sample.int(7,81,replace=TRUE),major=sample.int(7,81,replace=TRUE),level=sample.int(5,81,replace=TRUE),use=sample.int(4,81,replace=TRUE),rel=sample.int(5,81,replace=TRUE))

df<-prac %>% 
  as.matrix() %>% 
  unname()


```


Now we can add some settings on how big we want the groups to be or how many groups we want. For example if out a class of 80 we want group sizes of 4 we would need to tell the algorithm to make 20 groups. Since there might be an uneven number (like 83) we'll tweak the max allowed in a group. For balanced sorting all groups must have at least one representative from each group. So the minimum size will be a rounding of the number of responses.

```{r}
group_size=5
groups=floor(length(df[,1])/group_size)
```

Unfortunately, the next step requires us to step away from R because no one has developed an appropriate package for the algorithm we're trying to use. Luckily for us, Quarto with `reticulate` makes running python and R code in the same workflow relatively easy. First we transfer the needed data from the R side to python suitable frames. Next we need to bring in the packages python needs to use for the algorithm. This is just like loading `library(tidyverse)` in R. Python also lets us name the package for our own personal uses. Personally, I rarely deviate from the authors recommendation. Next we set up the algorithm settings. Then call the algorithm with a specific call much like we would in a TidyModels set up in R. We store the output in `labels` which is a vector of `[0:4]` of each students classification^[Reminder Python uses base 0. So the first index starts at 0 instead of 1 like in R]. 

```{python}
x=r.df
group=int(r.groups)
size=int(r.group_size)


from k_means_constrained import KMeansConstrained

import numpy as np

clf=KMeansConstrained(
  n_clusters=size,
  size_min=group,
  size_max=group+2,
  random_state=0
)



labels=clf.fit_predict(x)
```

Next, we bring the labels from python to R with a quick `reticulate::py` call. To add true randomness into the assignments, I make a function to mix up the names of each person in the clusters, and then apply to all using `purrr:map`. From there it's a matter of converting the list into a usable dataframe while maintaining all the names. List data manipulation is almost more of an art than a science. Do whatever you need to do to make it work for your problem. Here I want to keep a general structure because I don't know how many people will fill out the form beforehand.

```{r}
library(reticulate)
clus_labels<-py$labels

prac$labels=clus_labels+1 ## REPLACE PRAC WITH LIKERT BY DEMO  Keep the add 1 becuase of python base 0
prac$name=stringi::stri_rand_strings(length(prac$labels),6)

prac

```

Checkout the list of "students" above. If you squint, you can see how some labels seem to match relatively well. For example the 1st student as 1s across all input and was put into group 5 (labels=5). The next member of group 5, student 13, also has quite a bit of 1 survery responses so it makes sense that they should be grouped together. 

Let's check to see if the groups are balanced with similar number of students in each.

```{r}

prac %>% 
  group_by(labels) %>% 
  summarize(n=n())

```

All the groups are well balanced. Next I make a function to mix up the students by sampling from each group the required number of times. Because of some potential inbalances, I have to fill empty spaces with NAs.

```{r}
## mix up function

mix<-function(data,group){
  df_filter<-data %>% 
      filter(labels==group)
    
  out=sample(df_filter$name,size=length(df_filter$labels))
  
  return(out)
}


group_list<-1:5 |>
  map(\(x) mix(prac,x))
  

tdf<-as.data.frame(t(plyr::ldply(group_list,rbind)))

#Adjust colnames to show teammate
colnames(tdf)<-c(paste0("teammate",1:group_size))


na_vec<-unlist(tdf[(groups+1):(length(tdf[,1])),]) %>% 
  na.omit()

na_vec

add_vec<-c(na_vec,rep("NA",times=(groups-length(na_vec))))
add_vec

tdf=tdf[1:groups,]


tdf$teammate6<-add_vec

tdf



```

Voila! At the end we have a random, but skill balanced mixture of students in the number of groups that I want.
